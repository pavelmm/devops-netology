# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

```

Поиск текущую операци командой:  
       db.currentOp()
Завершим процесс по opid
       db.killOp()

Чтобы не было долгих запросов, необходимо добавить/создать соответствующий индекс
```

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

```

Redis является однопоточным приложением. Предпологаю, что проблема связана с исчерпанием ресурсов оперативной памяти. 

Доработка

Redis часто обслуживает большое количество запросов в секунду на экземпляр.
Некоторые команды выполняются быстро и выполняются в постоянное или логарифмическое время, другие команды представляют собой более медленные команды O(N) , которые могут вызывать пики задержки:

1.В Redis можно изменить задержки командой redis-cli --latency -h `host` -p `port`
2.Задержка, создаваемая форком. Чтобы сгенерировать файл RDB в фоновом режиме или перезаписать файл только для добавления, если включено сохранение AOF, Redis должен разветвить фоновые процессы.
3.Задержка, вызванная сетью и связью(задержка сети со скоростью 1 Гбит/с составляет около 200 мкс)
4.Задержка, вызванная огромными страницами можно отключить echo never > /sys/kernel/mm/transparent_hugepage/enabled
5.Задержка, вызванная swapp проверить посмотреть можно iostat 
6. Задержка диска. write(2) может блокироваться как при общесистемной синхронизации, так и при заполнении выходных буферов, когда ядру требуется очистить диск, чтобы принять новые записи. Вызов fdatasync(2) является худшим источником задержки, так как при использовании многих комбинаций ядер и файловых систем его выполнение может занять от нескольких миллисекунд до нескольких секунд,
7.Задержка, вызванная истечением срока действия. Redis удаляет ключи с истекшим сроком действия двумя способами: Запрашивается командой, но оказывается, что срок его действия уже истек. Истекает через несколько ключей каждые 100 миллисекунд.

Механизм блокировки, реализованный на основе Redis, в основном полагается на атомарные операции самого Redis.
Ключ устанавливается только тогда, когда ключ не существует. Действие значения ключа SET NX эквивалентно значению ключа SETNX
PX миллисекунда: установка времени истечения срока действия ключ Миллисекунды миллисекунды, когда время превышает это время, установленный ключ автоматически становится недействительным. Можно выполнить команду SET user_key user_value NX PX 100
Потому что эта команда успешно выполняется только тогда, когда определенный ключ не существует. Тогда, когда несколько процессов одновременно устанавливают один и тот же ключ в одно и то же время, только один процесс всегда будет успешным. Разблокировка очень проста, нужно только удалить этот ключ, но перед удалением нужно оценить, значение, соответствующее этому ключу.

ключи, срок действия которых истекает в один и тот же момент, могут быть источником задержки.
лучше включить механизмы завешения долгих запросов, и поменять таймауты.
```
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

```
Предполагаю что ошибки начали возникать из-за роста нагрузки. 
В качестве решения можно предложить:
   1. Увеличить значение параметров : connect_timeout, interactive_timeout, wait_timeout
   2. Добавить ресурсов на машине
   3. Создать индексы для оптимизации  и ускорения запросов (определить по плану запросов)

Так же могут быть сбои на сетевой инфраструктуре, в таком случае необходимо увеличивать net_read_timeout
Как дополнительный вариант можно расширить максимальное число соединений :  max_connections
```

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

```
Причина в недостатке ресурсов оперативной памяти, в результате ОС завершает процессы утилизирующие память, чтобы предотвратить падение всей системы.
Для предотвращения сбоев , необходимо увеличить объем ОЗУ или выставить ограничение в настройках PG на использование ресурсов хоста, 
чтобы исключить потребление всех ресурсов на машине.

OOM-Killer вызывается всякий раз, когда физическая память исчерпывается не только пользовательским приложением, но и работой в ядре.
Я думаю, что для того, чтобы избежать этой проблемы, нужно увеличение физической памяти и создание/увеличение swap. Увеличение как физической памяти, так и области подкачки легко понять, но увеличение физической памяти не является программным решением.

Доработка:

Postgresql не потребляет много памяти в отличии от java. Если все работало стабильно но вдруг, что-то пошло не так и пользователи ругаются то нужно зайти в моноторинг и посмотреть процессы которые заняли всю память постараться разобрать по чему так произошло. Если не критично для приложения завершить этот принцесс. Всё зависит от конкретной ситуации. 

То что время от времени база становится недоступно нужно проверять и смотреть логи по чему она недоступна : возможно сетевые проблемы, возможно причина перехода на новую версию приложения или перехода на другую БД.

Нашел ссылку как раз на эту тему. (Отладка и устранение проблем в PostgreSQL Streaming Replication) - https://itnan.ru/post.php?c=1&p=414111

<b>Нет у нас памяти все, закончились поставки</b>

Возможно если после перехода на PostgreSql изначально нехватает памяти то, как вариант нужно произвести оптимизацию парметров:

shared_buffers (integer): по умолчанию это обычно 128 мегабайт (128MB). Это значение не должно быть меньше 128 килобайт. Если использовать выделенный сервер с объёмом ОЗУ 1 ГБ и более, разумным начальным значением shared_buffers будет 25% от объёма памяти. В системах с объёмом ОЗУ меньше 1 ГБ стоит ограничиться меньшим процентом ОЗУ, чтобы оставить достаточно места операционной системе.

huge_pages (enum): Определяет, будут ли огромные страницы запрашиваться из основной области общей памяти. Допустимые значения: try (по умолчанию), on и off. Когда параметр huge_pages равен try, сервер будет пытаться запрашивать огромные страницы, но если это ему не удастся, вернётся к стандартному поведению. Со значением on, если получить огромные страницы не удастся, сервер не будет запущен.  Со значением off большие страницы не будут запрашиваться. Когда значение "on" это приводит к снижению быстродействия PostgreSQL.

temp_buffers (integer): Задаёт максимальный объём памяти, выделяемой для временных буферов в каждом сеансе. 
max_prepared_transactions (integer) :Задаёт максимальное число транзакций, которые могут одновременно находиться в «подготовленном» состоянии.

work_mem (integer): Задаёт базовый максимальный объём памяти, который будет использоваться во внутренних операциях при обработке запросов 

hash_mem_multiplier (floating point): Используется для определения максимального объёма памяти, который может выделяться для операций с хешированием

maintenance_work_mem (integer): Задаёт максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX и ALTER TABLE ADD FOREIGN KEY

autovacuum_work_mem (integer): Задаёт максимальный объём памяти, который будет использовать каждый рабочий процесс автоочистки. 

logical_decoding_work_mem (integer): Задаёт максимальный объём памяти, используемой для логического декодирования, после превышения которого некоторые декодированные изменения будут вымещаться на локальный диск.

max_stack_depth (integer): Задаёт максимальную безопасную глубину стека для исполнителя.

shared_memory_type (enum): Выбирает механизм разделяемой памяти, используя который сервер будет работать с основной областью общей памяти, содержащей общие буферы PostgreSQL и другие общие данные.

dynamic_shared_memory_type (enum): Выбирает механизм динамической разделяемой памяти, который будет использоваться сервером.

Если не вводить опреденные настройки в параметры, то будет выбран вариант по умолчанию и этот вариант не всегда правильный для оптимизации и корректной работы данной системы. По этому требуется дополнтельная настройка и проверка работоспособности системы.

Доработка для Redis, когда нет памяти

Переключиться на 32-битную версию. Redis предоставляет следующую статистику для 64-битной машины. 64-разрядная версия имеет больше доступной памяти по сравнению с 32-разрядной машиной. Но размер данных не превышает 3 Гб, то хранение в 32 битах — хороший вариант. 64-разрядные системы используют значительно больше памяти, чем 32-разрядные системы, для хранения одних и тех же ключей, особенно если ключи и значения имеют небольшой размер. Это связано с тем, что малым ключам выделяются полные 64 бита, что приводит к потере неиспользуемых битов. Когда размер данных увеличится более чем на 3 ГБ, нужно использовать 64 бита.

Быстрее восстанавливайте память ключей с истекшим сроком действия. Redis потребляет память для хранения ключей, срок действия которых уже истек. Как быстрее восстановить память просроченных ключей: перезагрузить сервер. Увеличьте выборки памяти в redis conf. Вы можете настроить задание cron для запуска сканирования или величить срок дествия ключей.
Ноесть и другой подход с ключами. Когда в Redis появилось очень много долгоживущих ключей. Redis брал 20 случайных ключей, большая часть из которых относилась к «долгожителям». Алгоритм стал часто недобирать 25% удаленных ключей для запуска следующей итерации. В памяти стало хранится гораздо больше просроченных результатов поиска, которые зря занимают память. вследствии получили большее потребление ОЗУ и нестабильный кластер. Нужно уменьшить время жизни этих записей.

Объединение небольших строк в хэши уменьшает объем используемой памяти и, в свою очередь, снижает затраты. Но есть нюанс. Производительность имеет свою цену. Преобразовывая строки в хеш, мы экономим память, потому что сохраняется только строковое значение, а не дополнительная информация, такая как: idle time, expiration, object reference count, и encodingсвязанная с ней. Но если нам нужен ключ со значением истечения срока действия, мы не можем связать его с хэш-структурой, поскольку срок действия недоступен. Решение зависит от количества строк, если их меньше 1 миллиона и потребление памяти невелико, преобразование происходит не сильно и нет смысла усложнять код. Но если строк больше 1 миллиона и потребление памяти велико, то этот подход обязательно следует использовать.

Преобразование хеш-таблицы в ziplist для хэшей. Уменьшает потребление памяти, но за это приходится платить, поскольку для изменения размера и получения записи требуется больше времени. Следовательно, увеличивается задержка и, возможно, увеличивается загрузка ЦП на сервере Redis.

Использовать короткие имена ключей уменьшает потребление памяти

Преобразование в список вместо хеша. это может сэкономить память, надо использовать этот подход только в том случае, если есть тысячи хэшей и если каждый из этих хэшей имеет похожие поля.

Разделить большие хэши на маленькие хэши. шардинг 

Сжатие строк длинных и малоиспользуемых. Эможет сэкономить вам от 30 до 50% памяти. Сжимая строки - уменьшаем пропускную способность сети между приложением и базами данных Redis.


Нужно проверить конфигурацию и ограничить оборудование 







```

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
