# Домашнее задание к занятию "13.2 разделы и монтирование"
Приложение запущено и работает, но время от времени появляется необходимость передавать между бекендами данные. А сам бекенд генерирует статику для фронта. Нужно оптимизировать это.
Для настройки NFS сервера можно воспользоваться следующей инструкцией (производить под пользователем на сервере, у которого есть доступ до kubectl):
* установить helm: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
* добавить репозиторий чартов: helm repo add stable https://charts.helm.sh/stable && helm repo update
* установить nfs-server через helm: helm install nfs-server stable/nfs-server-provisioner

В конце установки будет выдан пример создания PVC для этого сервера.

## Задание 1: подключить для тестового конфига общую папку
В stage окружении часто возникает необходимость отдавать статику бекенда сразу фронтом. Проще всего сделать это через общую папку. Требования:
* в поде подключена общая папка между контейнерами (например, /static);
* после записи чего-либо в контейнере с беком файлы можно получить из контейнера с фронтом.


<details><summary>Установка provisioner nfs</summary>

```
p@p:~/del/z$  curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 11156  100 11156    0     0  36457      0 --:--:-- --:--:-- --:--:-- 36457
Downloading https://get.helm.sh/helm-v3.10.1-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
helm installed into /usr/local/bin/helm
p@p:~/del/z$ helm repo add stable https://charts.helm.sh/stable && helm repo update
"stable" has been added to your repositories
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "stable" chart repository
Update Complete. ⎈Happy Helming!⎈
p@p:~/del/z$ sudo helm install nfs-server stable/nfs-server-provisioner
Error: INSTALLATION FAILED: repo stable not found
p@p:~/del/z$  helm install nfs-server stable/nfs-server-provisioner
WARNING: This chart is deprecated
NAME: nfs-server
LAST DEPLOYED: Sat Oct 29 14:36:57 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The NFS Provisioner service has now been installed.

A storage class named 'nfs' has now been created
and is available to provision dynamic volumes.

You can use this storageclass by creating a `PersistentVolumeClaim` with the
correct storageClassName attribute. For example:

    ---
    kind: PersistentVolumeClaim
    apiVersion: v1
    metadata:
      name: test-dynamic-volume-claim
    spec:
      storageClassName: "nfs"
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
p@p:~/del/z$ 

```

</details>


<details><summary>pod-int-volumes.yaml</summary>

```
# Config Pod with volume from lesson
apiVersion: v1
kind: Pod
metadata:
  name: pod-int-volumes
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - mountPath: "/static"
          name: static
    - name: busybox
      image: busybox
      command: ["sleep", "3600"]
      volumeMounts:
        - mountPath: "/tmp/cache"
          name: static
  volumes:
    - name: static
      emptyDir: {}

```

</details>

<details><summary></summary>

```
p@p:~/del/z$ kubectl apply -f pod-int-volumes.yaml 
pod/pod-int-volumes created
p@p:~/del/z$ kubectl get pods,pv,pvc
NAME                                      READY   STATUS    RESTARTS   AGE
pod/fb-pod-7644b6776f-6df4g               2/2     Running   0          24m
pod/nfs-server-nfs-server-provisioner-0   1/1     Running   0          64s
pod/pod-int-volumes                       2/2     Running   0          13s
pod/postgres-0                            1/1     Running   0          9m57s
pod/postgres-db-0                         1/1     Running   0          24m
pod/prod-b-5b9858c56c-7spcj               1/1     Running   0          9m58s
pod/prod-b-5b9858c56c-ngq6m               1/1     Running   0          9m58s
pod/prod-f-cb676886b-z8mtq                1/1     Running   0          9m58s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                    STORAGECLASS   REASON   AGE
persistentvolume/db-nfs-share                               2Gi        RWX            Retain           Available                                                                    60m
persistentvolume/nfs-pv                                     1Gi        RWX            Retain           Available                                                                    24m
persistentvolume/nfs-pv-prod                                1Gi        RWX            Retain           Available                                                                    9m57s
persistentvolume/pvc-053b422c-fb34-4b08-9f45-b15d623f813b   1Gi        RWX            Delete           Bound       default/postgredb-postgres-0             standard                9m57s
persistentvolume/pvc-ce2484a8-0681-40c4-9a72-c72fb601e669   1Gi        RWX            Delete           Bound       default/postgres-db-disk-postgres-db-0   standard                24m

NAME                                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/postgredb-postgres-0             Bound    pvc-053b422c-fb34-4b08-9f45-b15d623f813b   1Gi        RWX            standard       9m57s
persistentvolumeclaim/postgres-db-disk-postgres-db-0   Bound    pvc-ce2484a8-0681-40c4-9a72-c72fb601e669   1Gi        RWX            standard       24m
p@p:~/del/z$

```

</details>


<details><summary>Пишем в контейнере busybox</summary>

```
p@p:~/del/z$ kubectl exec pod-int-volumes -c busybox -- sh -c 'echo "test" > /tmp/cache/test.txt'
p@p:~/del/z$ kubectl exec pod-int-volumes -c busybox -- ls -la /tmp/cache
total 12
drwxrwxrwx    2 root     root          4096 Oct 29 11:41 .
drwxrwxrwt    1 root     root          4096 Oct 29 11:39 ..
-rw-r--r--    1 root     root             5 Oct 29 11:41 test.txt
p@p:~/del/z$ kubectl exec pod-int-volumes -c nginx -- ls -la /static
total 12
drwxrwxrwx 2 root root 4096 Oct 29 11:41 .
drwxr-xr-x 1 root root 4096 Oct 29 11:37 ..
-rw-r--r-- 1 root root    5 Oct 29 11:41 test.txt
p@p:~/del/z$ kubectl exec pod-int-volumes -c nginx -- sh -c 'cat /static/test.txt'
test

```

</details>


<details><summary>Проверяем в контейнере nginx</summary>
  
```
p@p:~/del/z$ kubectl exec pod-int-volumes -c nginx -- ls -la /static
total 12
drwxrwxrwx 2 root root 4096 Oct 29 17:44 .
drwxr-xr-x 1 root root 4096 Oct 29 17:41 ..
-rw-r--r-- 1 root root    5 Oct 29 17:44 test.txt
p@p:~/del/z$  kubectl exec pod-int-volumes -c nginx -- sh -c 'cat /static/test.txt'
test

  
```

</details>



## Задание 2: подключить общую папку для прода
Поработав на stage, доработки нужно отправить на прод. В продуктиве у нас контейнеры крутятся в разных подах, поэтому потребуется PV и связь через PVC. Сам PV должен быть связан с NFS сервером. Требования:
* все бекенды подключаются к одному PV в режиме ReadWriteMany;
* фронтенды тоже подключаются к этому же PV с таким же режимом;
* файлы, созданные бекендом, должны быть доступны фронту.


<details><summary>pvc.yaml</summary>

```

```

</details>


<details><summary>Результат pvc.yaml</summary>

```
p@p:~/del/z$ kubectl create -f pvc.yaml 
Error from server (AlreadyExists): error when creating "pvc.yaml": persistentvolumeclaims "shared" already exists
p@p:~/del/z$ kubectl get pvc
NAME                             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
postgredb-postgres-0             Bound     pvc-eac5fee8-4880-4c12-89bb-85a1ab9813ea   1Gi        RWX            standard       4h2m
postgres-db-disk-postgres-db-0   Bound     pvc-4a579229-cae1-48db-bad6-32e225944bbf   1Gi        RWX            standard       4h2m
shared                           Pending                                                                        nfs            3h10m

  
```

</details>

<details><summary>front-v2.yaml</summary>

```

# Config Front Deployment with PVC v2 (13.2)
apiVersion: apps/v1
kind: Deployment
metadata:
    name: prod-f-v2
spec:
    replicas: 1
    selector:
        matchLabels:
            app: ecommerce
            tier: front-v2
    template:
        metadata:
            labels:
                app: ecommerce
                tier: front-v2
        spec:
          containers:
          - name: client
            image: chrischinchilla/humanitech-product-fe
            imagePullPolicy: "IfNotPresent"
            ports:
            - name: http
              containerPort: 8080
            env:
            - name: PROD_B_V2_SERVER_URL
              value: prod-b-v2
            volumeMounts:
            - name: data
              mountPath: /mnt/nfs   
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: shared
# Config Front Service
---
apiVersion: v1
kind: Service
metadata:
    name: prod-f-v2
spec:
    type: NodePort
    ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
    selector:
        app: ecommerce
        tier: front-v2  
  
```

</details>


<details><summary>back-v2.yaml</summary>

```
# Config Back Deployment with PVC v2 (13.2)
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: ecommerce
    tier: back-v2
  name: prod-b-v2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ecommerce
      tier: back-v2
  template:
    metadata:
      labels:
        app: ecommerce
        tier: back-v2
    spec:
      containers:
      - env:
        - name: DATABASE_HOST
          value: postgres
        - name: DATABASE_NAME
          value: product
        - name: DATABASE_PASSWORD
          value: pr0dr0b0t
        - name: DATABASE_USER
          value: product_robot
        - name: DATABASE_PORT
          value: "5432"
        image: chrischinchilla/humanitech-product-be
        imagePullPolicy: "IfNotPresent"
        name: prod-b-v2
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: data
          mountPath: /mnt/nfs   
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: shared
# config back service
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: ecommerce
    tier: back-v2
  name: prod-b-v2
spec:
  type: NodePort
  ports:
  - name: "8080"
    port: 8080
    targetPort: 8080
  selector:
    app: ecommerce
    tier: back-v2
  
```

</details>


</details>

<details><summary>Создал и запустил поды front-v2.yaml и back-v2.yaml</summary>

```

p@p:~/del/z$ kubectl apply -f back-v2.yaml -f front-v2.yaml 
deployment.apps/prod-b-v2 created
service/prod-b-v2 created
deployment.apps/prod-f-v2 created
service/prod-f-v2 created
  
  
```

</details>


</details>

<details><summary></summary>

```

p@p:~/del/z$ kubectl get pod,pvc,deploy
NAME                                      READY   STATUS    RESTARTS   AGE
pod/fb-pod-7644b6776f-6df4g               2/2     Running   0          32m
pod/nfs-server-nfs-server-provisioner-0   1/1     Running   0          8m35s
pod/pod-int-volumes                       2/2     Running   0          7m44s
pod/postgres-0                            1/1     Running   0          17m
pod/postgres-db-0                         1/1     Running   0          31m
pod/prod-b-5b9858c56c-7spcj               1/1     Running   0          17m
pod/prod-b-5b9858c56c-ngq6m               1/1     Running   0          17m
pod/prod-b-v2-68c79645d4-8ds8g            1/1     Running   0          13s
pod/prod-b-v2-68c79645d4-gfpfm            1/1     Running   0          13s
pod/prod-f-cb676886b-z8mtq                1/1     Running   0          17m
pod/prod-f-v2-58bd58b596-6w7xn            1/1     Running   0          13s

NAME                                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/postgredb-postgres-0             Bound    pvc-053b422c-fb34-4b08-9f45-b15d623f813b   1Gi        RWX            standard       17m
persistentvolumeclaim/postgres-db-disk-postgres-db-0   Bound    pvc-ce2484a8-0681-40c4-9a72-c72fb601e669   1Gi        RWX            standard       31m
persistentvolumeclaim/shared                           Bound    pvc-99abe6c3-14b8-4771-b6b1-c38e6eb20cb5   1Gi        RWX            nfs            2m16s

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/fb-pod      1/1     1            1           32m
deployment.apps/prod-b      2/2     2            2           17m
deployment.apps/prod-b-v2   2/2     2            2           13s
deployment.apps/prod-f      1/1     1            1           17m
deployment.apps/prod-f-v2   1/1     1            1           13s  
  
```

</details>


</details>

<details><summary></summary>

```

  
  
```

</details>


</details>

<details><summary></summary>

```

  
  
```

</details>


</details>

<details><summary></summary>

```

  
  
```

</details>



---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
