# Домашнее задание к занятию "13.2 разделы и монтирование"
Приложение запущено и работает, но время от времени появляется необходимость передавать между бекендами данные. А сам бекенд генерирует статику для фронта. Нужно оптимизировать это.
Для настройки NFS сервера можно воспользоваться следующей инструкцией (производить под пользователем на сервере, у которого есть доступ до kubectl):
* установить helm: curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
* добавить репозиторий чартов: helm repo add stable https://charts.helm.sh/stable && helm repo update
* установить nfs-server через helm: helm install nfs-server stable/nfs-server-provisioner

В конце установки будет выдан пример создания PVC для этого сервера.

## Задание 1: подключить для тестового конфига общую папку
В stage окружении часто возникает необходимость отдавать статику бекенда сразу фронтом. Проще всего сделать это через общую папку. Требования:
* в поде подключена общая папка между контейнерами (например, /static);
* после записи чего-либо в контейнере с беком файлы можно получить из контейнера с фронтом.


<details><summary>Установка provisioner nfs</summary>

```
p@p:~/del/z$  curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 11156  100 11156    0     0  36457      0 --:--:-- --:--:-- --:--:-- 36457
Downloading https://get.helm.sh/helm-v3.10.1-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
helm installed into /usr/local/bin/helm
p@p:~/del/z$ helm repo add stable https://charts.helm.sh/stable && helm repo update
"stable" has been added to your repositories
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "stable" chart repository
Update Complete. ⎈Happy Helming!⎈
p@p:~/del/z$ sudo helm install nfs-server stable/nfs-server-provisioner
Error: INSTALLATION FAILED: repo stable not found
p@p:~/del/z$  helm install nfs-server stable/nfs-server-provisioner
WARNING: This chart is deprecated
NAME: nfs-server
LAST DEPLOYED: Sat Oct 29 14:36:57 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
The NFS Provisioner service has now been installed.

A storage class named 'nfs' has now been created
and is available to provision dynamic volumes.

You can use this storageclass by creating a `PersistentVolumeClaim` with the
correct storageClassName attribute. For example:

    ---
    kind: PersistentVolumeClaim
    apiVersion: v1
    metadata:
      name: test-dynamic-volume-claim
    spec:
      storageClassName: "nfs"
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi
p@p:~/del/z$ 

```

</details>


<details><summary>pod-int-volumes.yaml</summary>

```
# Config Pod with volume from lesson
apiVersion: v1
kind: Pod
metadata:
  name: pod-int-volumes
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - mountPath: "/static"
          name: static
    - name: busybox
      image: busybox
      command: ["sleep", "3600"]
      volumeMounts:
        - mountPath: "/tmp/cache"
          name: static
  volumes:
    - name: static
      emptyDir: {}

```

</details>

<details><summary></summary>

```
p@p:~/del/z$ kubectl apply -f pod-int-volumes.yaml 
pod/pod-int-volumes created
p@p:~/del/z$ kubectl get pods,pv,pvc
NAME                                      READY   STATUS    RESTARTS   AGE
pod/fb-pod-7644b6776f-6df4g               2/2     Running   0          24m
pod/nfs-server-nfs-server-provisioner-0   1/1     Running   0          64s
pod/pod-int-volumes                       2/2     Running   0          13s
pod/postgres-0                            1/1     Running   0          9m57s
pod/postgres-db-0                         1/1     Running   0          24m
pod/prod-b-5b9858c56c-7spcj               1/1     Running   0          9m58s
pod/prod-b-5b9858c56c-ngq6m               1/1     Running   0          9m58s
pod/prod-f-cb676886b-z8mtq                1/1     Running   0          9m58s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                    STORAGECLASS   REASON   AGE
persistentvolume/db-nfs-share                               2Gi        RWX            Retain           Available                                                                    60m
persistentvolume/nfs-pv                                     1Gi        RWX            Retain           Available                                                                    24m
persistentvolume/nfs-pv-prod                                1Gi        RWX            Retain           Available                                                                    9m57s
persistentvolume/pvc-053b422c-fb34-4b08-9f45-b15d623f813b   1Gi        RWX            Delete           Bound       default/postgredb-postgres-0             standard                9m57s
persistentvolume/pvc-ce2484a8-0681-40c4-9a72-c72fb601e669   1Gi        RWX            Delete           Bound       default/postgres-db-disk-postgres-db-0   standard                24m

NAME                                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/postgredb-postgres-0             Bound    pvc-053b422c-fb34-4b08-9f45-b15d623f813b   1Gi        RWX            standard       9m57s
persistentvolumeclaim/postgres-db-disk-postgres-db-0   Bound    pvc-ce2484a8-0681-40c4-9a72-c72fb601e669   1Gi        RWX            standard       24m
p@p:~/del/z$

```

</details>


<details><summary>Пишем в контейнере busybox</summary>

```
p@p:~/del/z$ kubectl exec pod-int-volumes -c busybox -- sh -c 'echo "test" > /tmp/cache/test.txt'
p@p:~/del/z$ kubectl exec pod-int-volumes -c busybox -- ls -la /tmp/cache
total 12
drwxrwxrwx    2 root     root          4096 Oct 29 11:41 .
drwxrwxrwt    1 root     root          4096 Oct 29 11:39 ..
-rw-r--r--    1 root     root             5 Oct 29 11:41 test.txt
p@p:~/del/z$ kubectl exec pod-int-volumes -c nginx -- ls -la /static
total 12
drwxrwxrwx 2 root root 4096 Oct 29 11:41 .
drwxr-xr-x 1 root root 4096 Oct 29 11:37 ..
-rw-r--r-- 1 root root    5 Oct 29 11:41 test.txt
p@p:~/del/z$ kubectl exec pod-int-volumes -c nginx -- sh -c 'cat /static/test.txt'
test

```

</details>


<details><summary>Проверяем в контейнере nginx</summary>

```

```

</details>

<details><summary></summary>

```

```

</details>


<details><summary></summary>

```

```

</details>

<details><summary></summary>

```

```

</details>


<details><summary></summary>

```

```

</details>

## Задание 2: подключить общую папку для прода
Поработав на stage, доработки нужно отправить на прод. В продуктиве у нас контейнеры крутятся в разных подах, поэтому потребуется PV и связь через PVC. Сам PV должен быть связан с NFS сервером. Требования:
* все бекенды подключаются к одному PV в режиме ReadWriteMany;
* фронтенды тоже подключаются к этому же PV с таким же режимом;
* файлы, созданные бекендом, должны быть доступны фронту.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
